# @package _global_

# to execute this experiment run:
# python train.py experiment=<name>
defaults:
  - /callbacks: default
  - override /model: metrics_drought # standard metrics for drought
  - override /data: prep_drought_landsat
  - override /trainer: default

ckpt_path: null

model:
  _target_: src.models.lightning_wrapper.ExtremesLightningWrapper
  net:
    _target_: src.models.spatial_temporal_nn.SpatialTemporalNN
    spatial:
      _target_: src.models.cnn.ResNet
      variant: 18
      n_input_channels:
        _target_: src.utils.utils.get_length
        obj: ${data.bands}
      num_classes: 0 # without num_classes use flatten + input_dim
      pool:
        _target_: torch.nn.AdaptiveAvgPool2d
        output_size: [1,1]
    activation:
      _target_: torch.nn.Sequential
      _args_: # bring down channel dim and flatten
        - _target_: torch.nn.Conv2d
          in_channels: 512
          out_channels: 32
          kernel_size: 1
        - _target_: torch.nn.Flatten
    temporal:
      _target_: src.models.lstm.LSTM
      input_dim: 32
      num_classes: ${model.num_classes}
      hidden_dims: 128
      num_layers: 3
      dropout: 0.15
      bidirectional: False
      use_layernorm: True
      return_sequence: True

  output_activation_function:
    _target_: torch.nn.Identity

  loss:
    _target_: torch.nn.CrossEntropyLoss
    reduction: none
  optimizer:
    _target_: torch.optim.Adam
    _partial_: true
    lr: 0.001
    weight_decay: 0.
  scheduler:
    _target_: torch.optim.lr_scheduler.CosineAnnealingLR
    _partial_: true
    T_max: ${trainer.max_epochs}
    eta_min: 1e-5

seed:
    42
trainer:
    max_epochs: 60
    precision: 16-mixed
    accumulate_grad_batches: 2
